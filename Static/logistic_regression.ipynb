{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update sklearn to prevent version mismatches\n",
    "# !pip install sklearn --upgrade\n",
    "# install joblib to save model. \n",
    "# !pip install joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r X_train\n",
    "%store -r X_test\n",
    "%store -r y_train\n",
    "%store -r y_test\n",
    "%store -r X_train_scaled\n",
    "%store -r X_test_scaled \n",
    "%store -r X_train_stand\n",
    "%store -r X_test_stand"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "model = LogisticRegression(max_iter = 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jiaping/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/jiaping/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/jiaping/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/jiaping/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/jiaping/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The cross-validated accuracy for unprocessed training set:\n",
      "0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jiaping/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "model.fit(X_train, y_train)\n",
    "print(f\"The cross-validated accuracy for unprocessed training set:\\n{round(cross_val_score(model,X_train, y_train,scoring='accuracy', cv=5).mean(),2)}\")\n",
    "# failed to converge without data's being scaled or standardized: accuracy: 66%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The cross-validated accuracy for normalized training set: \n",
      "84.89%\n",
      "The cross-validated accuracy for standardized training set:\n",
      "88.67%\n"
     ]
    }
   ],
   "source": [
    "print(f\"The cross-validated accuracy for normalized training set: \\n{round(cross_val_score(model,X_train_scaled, y_train,scoring='accuracy', cv=5).mean()*100,2)}%\")\n",
    "print(f\"The cross-validated accuracy for standardized training set:\\n{round(cross_val_score(model,X_train_stand, y_train,scoring='accuracy', cv=5).mean()*100,2)}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Standardization produces higher cross-validated accuracy than normalization, so standardized data will be used for hyperparameter tuning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning\n",
    "\n",
    "Use `GridSearchCV` to tune the model's parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV,RandomizedSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "param_grid = {'C': [0.00001, 0.0001,0.001,0.01,0.1, 1, 10, 100, 1000], \n",
    "              'max_iter': [1000, 5000, 10000],\n",
    "              'penalty': [\"l1\", \"l2\"],\n",
    "              'solver': ['liblinear', 'lbfgs']}\n",
    "\n",
    "# Because the \"liblinear\" solver does not improve the model performance and also makes the search much slower compared to \"lbfgs\" solver\n",
    "# grid search about solver and penalty is deleted (lbfgs solver only deal with l2 penalty) for the gridsearch on standardized data\n",
    "param_grid2 = {'C': [0.00001, 0.0001,0.001,0.01,0.1, 1, 10, 100, 1000], \n",
    "              'max_iter': [1000, 5000, 10000]}\n",
    "model = LogisticRegression()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Normalized data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 108 candidates, totalling 540 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:    2.2s\n",
      "[Parallel(n_jobs=-1)]: Done 376 tasks      | elapsed:   25.7s\n",
      "[Parallel(n_jobs=-1)]: Done 540 out of 540 | elapsed:  4.8min finished\n",
      "/Users/jiaping/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=LogisticRegression(), n_jobs=-1,\n",
       "             param_grid={'C': [1e-05, 0.0001, 0.001, 0.01, 0.1, 1, 10, 100,\n",
       "                               1000],\n",
       "                         'max_iter': [1000, 5000, 10000],\n",
       "                         'penalty': ['l1', 'l2'],\n",
       "                         'solver': ['liblinear', 'lbfgs']},\n",
       "             verbose=3)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid1 = GridSearchCV(model, param_grid, verbose = 3, n_jobs = -1)\n",
    "grid1.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best paramaters for the tuned model: {'C': 1000, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "\n",
      "The cross-validated accuracy for the tuned model with normalized training set:88.9%\n"
     ]
    }
   ],
   "source": [
    "print(f\"The best paramaters for the tuned model: {grid1.best_params_}\\n\") \n",
    "print(f\"The cross-validated accuracy for the tuned model with normalized training set:{round(grid1.best_score_*100,2)}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After model tuning, the cross-validated accuracy is increased from 84.89% to 88.9%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results on the whole training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                precision    recall  f1-score   support\n",
      "\n",
      "     CANDIDATE       0.84      0.70      0.76      1586\n",
      "     CONFIRMED       0.76      0.86      0.81      1704\n",
      "FALSE POSITIVE       0.98      1.00      0.99      3268\n",
      "\n",
      "      accuracy                           0.89      6558\n",
      "     macro avg       0.86      0.85      0.85      6558\n",
      "  weighted avg       0.89      0.89      0.89      6558\n",
      "\n",
      "88.9%\n"
     ]
    }
   ],
   "source": [
    "predictions1 = grid1.predict(X_train_scaled)\n",
    "print(classification_report(y_train, predictions1))\n",
    "print(f\"{round(grid1.score(X_train_scaled, y_train)*100,2)}%\")  # 88.44%, 89.3%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Standardized data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 27 candidates, totalling 135 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  40 tasks      | elapsed:    0.9s\n",
      "[Parallel(n_jobs=-1)]: Done 135 out of 135 | elapsed:   33.1s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=LogisticRegression(), n_jobs=-1,\n",
       "             param_grid={'C': [1e-05, 0.0001, 0.001, 0.01, 0.1, 1, 10, 100,\n",
       "                               1000],\n",
       "                         'max_iter': [1000, 5000, 10000]},\n",
       "             verbose=3)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid2 = GridSearchCV(model, param_grid2, verbose = 3, n_jobs = -1)\n",
    "grid2.fit(X_train_stand, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best paramaters for the tuned model: {'C': 1000, 'max_iter': 5000}\n",
      "\n",
      "The cross-validated accuracy for the tuned model with standardized training set:89.04%\n"
     ]
    }
   ],
   "source": [
    "print(f\"The best paramaters for the tuned model: {grid2.best_params_}\\n\")\n",
    "print(f\"The cross-validated accuracy for the tuned model with standardized training set:{round(grid2.best_score_*100,2)}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After model tuning, the cross-validated accuracy is increased from 88.67% to 89.04%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results on the whole training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                precision    recall  f1-score   support\n",
      "\n",
      "     CANDIDATE       0.84      0.71      0.77      1586\n",
      "     CONFIRMED       0.77      0.86      0.82      1704\n",
      "FALSE POSITIVE       0.98      1.00      0.99      3268\n",
      "\n",
      "      accuracy                           0.89      6558\n",
      "     macro avg       0.87      0.86      0.86      6558\n",
      "  weighted avg       0.89      0.89      0.89      6558\n",
      "\n",
      "89.34%\n"
     ]
    }
   ],
   "source": [
    "predictions2 = grid2.predict(X_train_stand)\n",
    "print(classification_report(y_train, predictions2))\n",
    "print(f\"{round(grid2.score(X_train_stand, y_train)*100,2)}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The tuned model with standardized data perfoems slightly better than the tuned model with normalized data, as the cross-validated accuracy of the tuned model with standardized data (89.04%) is higher than the one with normalized data (88.9%).\n",
    "\n",
    "The final logistic regression model :\n",
    "1. Requires the standardization of data.\n",
    "2. Model parameters:  {'C': 10, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
    "3. Cross-validated accuracy: 89.04%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save the tuned model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['logistic_regression.sav']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "filename = 'logistic_regression.sav'\n",
    "joblib.dump(grid2, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
