{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update sklearn to prevent version mismatches\n",
    "# !pip install sklearn --upgrade\n",
    "# install joblib to save model. \n",
    "# !pip install joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import tensorflow\n",
    "import numpy as np\n",
    "import imblearn\n",
    "print(imblearn.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>koi_disposition</th>\n",
       "      <th>koi_fpflag_nt</th>\n",
       "      <th>koi_fpflag_ss</th>\n",
       "      <th>koi_fpflag_co</th>\n",
       "      <th>koi_fpflag_ec</th>\n",
       "      <th>koi_period</th>\n",
       "      <th>koi_period_err1</th>\n",
       "      <th>koi_period_err2</th>\n",
       "      <th>koi_time0bk</th>\n",
       "      <th>koi_time0bk_err1</th>\n",
       "      <th>...</th>\n",
       "      <th>koi_steff_err2</th>\n",
       "      <th>koi_slogg</th>\n",
       "      <th>koi_slogg_err1</th>\n",
       "      <th>koi_slogg_err2</th>\n",
       "      <th>koi_srad</th>\n",
       "      <th>koi_srad_err1</th>\n",
       "      <th>koi_srad_err2</th>\n",
       "      <th>ra</th>\n",
       "      <th>dec</th>\n",
       "      <th>koi_kepmag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CONFIRMED</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>54.418383</td>\n",
       "      <td>2.479000e-04</td>\n",
       "      <td>-2.479000e-04</td>\n",
       "      <td>162.513840</td>\n",
       "      <td>0.003520</td>\n",
       "      <td>...</td>\n",
       "      <td>-81</td>\n",
       "      <td>4.467</td>\n",
       "      <td>0.064</td>\n",
       "      <td>-0.096</td>\n",
       "      <td>0.927</td>\n",
       "      <td>0.105</td>\n",
       "      <td>-0.061</td>\n",
       "      <td>291.93423</td>\n",
       "      <td>48.141651</td>\n",
       "      <td>15.347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FALSE POSITIVE</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>19.899140</td>\n",
       "      <td>1.490000e-05</td>\n",
       "      <td>-1.490000e-05</td>\n",
       "      <td>175.850252</td>\n",
       "      <td>0.000581</td>\n",
       "      <td>...</td>\n",
       "      <td>-176</td>\n",
       "      <td>4.544</td>\n",
       "      <td>0.044</td>\n",
       "      <td>-0.176</td>\n",
       "      <td>0.868</td>\n",
       "      <td>0.233</td>\n",
       "      <td>-0.078</td>\n",
       "      <td>297.00482</td>\n",
       "      <td>48.134129</td>\n",
       "      <td>15.436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FALSE POSITIVE</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.736952</td>\n",
       "      <td>2.630000e-07</td>\n",
       "      <td>-2.630000e-07</td>\n",
       "      <td>170.307565</td>\n",
       "      <td>0.000115</td>\n",
       "      <td>...</td>\n",
       "      <td>-174</td>\n",
       "      <td>4.564</td>\n",
       "      <td>0.053</td>\n",
       "      <td>-0.168</td>\n",
       "      <td>0.791</td>\n",
       "      <td>0.201</td>\n",
       "      <td>-0.067</td>\n",
       "      <td>285.53461</td>\n",
       "      <td>48.285210</td>\n",
       "      <td>15.597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CONFIRMED</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.525592</td>\n",
       "      <td>3.760000e-06</td>\n",
       "      <td>-3.760000e-06</td>\n",
       "      <td>171.595550</td>\n",
       "      <td>0.001130</td>\n",
       "      <td>...</td>\n",
       "      <td>-211</td>\n",
       "      <td>4.438</td>\n",
       "      <td>0.070</td>\n",
       "      <td>-0.210</td>\n",
       "      <td>1.046</td>\n",
       "      <td>0.334</td>\n",
       "      <td>-0.133</td>\n",
       "      <td>288.75488</td>\n",
       "      <td>48.226200</td>\n",
       "      <td>15.509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CONFIRMED</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.134435</td>\n",
       "      <td>1.050000e-05</td>\n",
       "      <td>-1.050000e-05</td>\n",
       "      <td>172.979370</td>\n",
       "      <td>0.001900</td>\n",
       "      <td>...</td>\n",
       "      <td>-232</td>\n",
       "      <td>4.486</td>\n",
       "      <td>0.054</td>\n",
       "      <td>-0.229</td>\n",
       "      <td>0.972</td>\n",
       "      <td>0.315</td>\n",
       "      <td>-0.105</td>\n",
       "      <td>296.28613</td>\n",
       "      <td>48.224670</td>\n",
       "      <td>15.714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6986</th>\n",
       "      <td>FALSE POSITIVE</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>8.589871</td>\n",
       "      <td>1.846000e-04</td>\n",
       "      <td>-1.846000e-04</td>\n",
       "      <td>132.016100</td>\n",
       "      <td>0.015700</td>\n",
       "      <td>...</td>\n",
       "      <td>-152</td>\n",
       "      <td>4.296</td>\n",
       "      <td>0.231</td>\n",
       "      <td>-0.189</td>\n",
       "      <td>1.088</td>\n",
       "      <td>0.313</td>\n",
       "      <td>-0.228</td>\n",
       "      <td>298.74921</td>\n",
       "      <td>46.973351</td>\n",
       "      <td>14.478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6987</th>\n",
       "      <td>FALSE POSITIVE</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.527699</td>\n",
       "      <td>1.160000e-07</td>\n",
       "      <td>-1.160000e-07</td>\n",
       "      <td>131.705093</td>\n",
       "      <td>0.000170</td>\n",
       "      <td>...</td>\n",
       "      <td>-166</td>\n",
       "      <td>4.529</td>\n",
       "      <td>0.035</td>\n",
       "      <td>-0.196</td>\n",
       "      <td>0.903</td>\n",
       "      <td>0.237</td>\n",
       "      <td>-0.079</td>\n",
       "      <td>297.18875</td>\n",
       "      <td>47.093819</td>\n",
       "      <td>14.082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6988</th>\n",
       "      <td>CANDIDATE</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.739849</td>\n",
       "      <td>1.780000e-05</td>\n",
       "      <td>-1.780000e-05</td>\n",
       "      <td>133.001270</td>\n",
       "      <td>0.007690</td>\n",
       "      <td>...</td>\n",
       "      <td>-220</td>\n",
       "      <td>4.444</td>\n",
       "      <td>0.056</td>\n",
       "      <td>-0.224</td>\n",
       "      <td>1.031</td>\n",
       "      <td>0.341</td>\n",
       "      <td>-0.114</td>\n",
       "      <td>286.50937</td>\n",
       "      <td>47.163219</td>\n",
       "      <td>14.757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6989</th>\n",
       "      <td>FALSE POSITIVE</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.681402</td>\n",
       "      <td>2.430000e-06</td>\n",
       "      <td>-2.430000e-06</td>\n",
       "      <td>132.181750</td>\n",
       "      <td>0.002850</td>\n",
       "      <td>...</td>\n",
       "      <td>-236</td>\n",
       "      <td>4.447</td>\n",
       "      <td>0.056</td>\n",
       "      <td>-0.224</td>\n",
       "      <td>1.041</td>\n",
       "      <td>0.341</td>\n",
       "      <td>-0.114</td>\n",
       "      <td>294.16489</td>\n",
       "      <td>47.176281</td>\n",
       "      <td>15.385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6990</th>\n",
       "      <td>FALSE POSITIVE</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4.856035</td>\n",
       "      <td>6.360000e-05</td>\n",
       "      <td>-6.360000e-05</td>\n",
       "      <td>135.993300</td>\n",
       "      <td>0.010800</td>\n",
       "      <td>...</td>\n",
       "      <td>-225</td>\n",
       "      <td>4.385</td>\n",
       "      <td>0.054</td>\n",
       "      <td>-0.216</td>\n",
       "      <td>1.193</td>\n",
       "      <td>0.410</td>\n",
       "      <td>-0.137</td>\n",
       "      <td>297.00977</td>\n",
       "      <td>47.121021</td>\n",
       "      <td>14.826</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6991 rows × 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     koi_disposition  koi_fpflag_nt  koi_fpflag_ss  koi_fpflag_co  \\\n",
       "0          CONFIRMED              0              0              0   \n",
       "1     FALSE POSITIVE              0              1              0   \n",
       "2     FALSE POSITIVE              0              1              0   \n",
       "3          CONFIRMED              0              0              0   \n",
       "4          CONFIRMED              0              0              0   \n",
       "...              ...            ...            ...            ...   \n",
       "6986  FALSE POSITIVE              0              0              0   \n",
       "6987  FALSE POSITIVE              0              1              1   \n",
       "6988       CANDIDATE              0              0              0   \n",
       "6989  FALSE POSITIVE              0              0              1   \n",
       "6990  FALSE POSITIVE              0              0              1   \n",
       "\n",
       "      koi_fpflag_ec  koi_period  koi_period_err1  koi_period_err2  \\\n",
       "0                 0   54.418383     2.479000e-04    -2.479000e-04   \n",
       "1                 0   19.899140     1.490000e-05    -1.490000e-05   \n",
       "2                 0    1.736952     2.630000e-07    -2.630000e-07   \n",
       "3                 0    2.525592     3.760000e-06    -3.760000e-06   \n",
       "4                 0    4.134435     1.050000e-05    -1.050000e-05   \n",
       "...             ...         ...              ...              ...   \n",
       "6986              1    8.589871     1.846000e-04    -1.846000e-04   \n",
       "6987              0    0.527699     1.160000e-07    -1.160000e-07   \n",
       "6988              0    1.739849     1.780000e-05    -1.780000e-05   \n",
       "6989              0    0.681402     2.430000e-06    -2.430000e-06   \n",
       "6990              1    4.856035     6.360000e-05    -6.360000e-05   \n",
       "\n",
       "      koi_time0bk  koi_time0bk_err1  ...  koi_steff_err2  koi_slogg  \\\n",
       "0      162.513840          0.003520  ...             -81      4.467   \n",
       "1      175.850252          0.000581  ...            -176      4.544   \n",
       "2      170.307565          0.000115  ...            -174      4.564   \n",
       "3      171.595550          0.001130  ...            -211      4.438   \n",
       "4      172.979370          0.001900  ...            -232      4.486   \n",
       "...           ...               ...  ...             ...        ...   \n",
       "6986   132.016100          0.015700  ...            -152      4.296   \n",
       "6987   131.705093          0.000170  ...            -166      4.529   \n",
       "6988   133.001270          0.007690  ...            -220      4.444   \n",
       "6989   132.181750          0.002850  ...            -236      4.447   \n",
       "6990   135.993300          0.010800  ...            -225      4.385   \n",
       "\n",
       "      koi_slogg_err1  koi_slogg_err2  koi_srad  koi_srad_err1  koi_srad_err2  \\\n",
       "0              0.064          -0.096     0.927          0.105         -0.061   \n",
       "1              0.044          -0.176     0.868          0.233         -0.078   \n",
       "2              0.053          -0.168     0.791          0.201         -0.067   \n",
       "3              0.070          -0.210     1.046          0.334         -0.133   \n",
       "4              0.054          -0.229     0.972          0.315         -0.105   \n",
       "...              ...             ...       ...            ...            ...   \n",
       "6986           0.231          -0.189     1.088          0.313         -0.228   \n",
       "6987           0.035          -0.196     0.903          0.237         -0.079   \n",
       "6988           0.056          -0.224     1.031          0.341         -0.114   \n",
       "6989           0.056          -0.224     1.041          0.341         -0.114   \n",
       "6990           0.054          -0.216     1.193          0.410         -0.137   \n",
       "\n",
       "             ra        dec  koi_kepmag  \n",
       "0     291.93423  48.141651      15.347  \n",
       "1     297.00482  48.134129      15.436  \n",
       "2     285.53461  48.285210      15.597  \n",
       "3     288.75488  48.226200      15.509  \n",
       "4     296.28613  48.224670      15.714  \n",
       "...         ...        ...         ...  \n",
       "6986  298.74921  46.973351      14.478  \n",
       "6987  297.18875  47.093819      14.082  \n",
       "6988  286.50937  47.163219      14.757  \n",
       "6989  294.16489  47.176281      15.385  \n",
       "6990  297.00977  47.121021      14.826  \n",
       "\n",
       "[6991 rows x 41 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../Resources/cleaned_data.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a Train Test Split\n",
    "\n",
    "Use `koi_disposition` for the y values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>koi_fpflag_nt</th>\n",
       "      <th>koi_fpflag_ss</th>\n",
       "      <th>koi_fpflag_co</th>\n",
       "      <th>koi_fpflag_ec</th>\n",
       "      <th>koi_period</th>\n",
       "      <th>koi_period_err1</th>\n",
       "      <th>koi_period_err2</th>\n",
       "      <th>koi_time0bk</th>\n",
       "      <th>koi_time0bk_err1</th>\n",
       "      <th>koi_time0bk_err2</th>\n",
       "      <th>...</th>\n",
       "      <th>koi_steff_err2</th>\n",
       "      <th>koi_slogg</th>\n",
       "      <th>koi_slogg_err1</th>\n",
       "      <th>koi_slogg_err2</th>\n",
       "      <th>koi_srad</th>\n",
       "      <th>koi_srad_err1</th>\n",
       "      <th>koi_srad_err2</th>\n",
       "      <th>ra</th>\n",
       "      <th>dec</th>\n",
       "      <th>koi_kepmag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>54.418383</td>\n",
       "      <td>2.479000e-04</td>\n",
       "      <td>-2.479000e-04</td>\n",
       "      <td>162.513840</td>\n",
       "      <td>0.003520</td>\n",
       "      <td>-0.003520</td>\n",
       "      <td>...</td>\n",
       "      <td>-81</td>\n",
       "      <td>4.467000</td>\n",
       "      <td>0.064000</td>\n",
       "      <td>-0.096000</td>\n",
       "      <td>0.927000</td>\n",
       "      <td>0.105000</td>\n",
       "      <td>-0.061000</td>\n",
       "      <td>291.934230</td>\n",
       "      <td>48.141651</td>\n",
       "      <td>15.347000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>19.899140</td>\n",
       "      <td>1.490000e-05</td>\n",
       "      <td>-1.490000e-05</td>\n",
       "      <td>175.850252</td>\n",
       "      <td>0.000581</td>\n",
       "      <td>-0.000581</td>\n",
       "      <td>...</td>\n",
       "      <td>-176</td>\n",
       "      <td>4.544000</td>\n",
       "      <td>0.044000</td>\n",
       "      <td>-0.176000</td>\n",
       "      <td>0.868000</td>\n",
       "      <td>0.233000</td>\n",
       "      <td>-0.078000</td>\n",
       "      <td>297.004820</td>\n",
       "      <td>48.134129</td>\n",
       "      <td>15.436000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.736952</td>\n",
       "      <td>2.630000e-07</td>\n",
       "      <td>-2.630000e-07</td>\n",
       "      <td>170.307565</td>\n",
       "      <td>0.000115</td>\n",
       "      <td>-0.000115</td>\n",
       "      <td>...</td>\n",
       "      <td>-174</td>\n",
       "      <td>4.564000</td>\n",
       "      <td>0.053000</td>\n",
       "      <td>-0.168000</td>\n",
       "      <td>0.791000</td>\n",
       "      <td>0.201000</td>\n",
       "      <td>-0.067000</td>\n",
       "      <td>285.534610</td>\n",
       "      <td>48.285210</td>\n",
       "      <td>15.597000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.525592</td>\n",
       "      <td>3.760000e-06</td>\n",
       "      <td>-3.760000e-06</td>\n",
       "      <td>171.595550</td>\n",
       "      <td>0.001130</td>\n",
       "      <td>-0.001130</td>\n",
       "      <td>...</td>\n",
       "      <td>-211</td>\n",
       "      <td>4.438000</td>\n",
       "      <td>0.070000</td>\n",
       "      <td>-0.210000</td>\n",
       "      <td>1.046000</td>\n",
       "      <td>0.334000</td>\n",
       "      <td>-0.133000</td>\n",
       "      <td>288.754880</td>\n",
       "      <td>48.226200</td>\n",
       "      <td>15.509000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.134435</td>\n",
       "      <td>1.050000e-05</td>\n",
       "      <td>-1.050000e-05</td>\n",
       "      <td>172.979370</td>\n",
       "      <td>0.001900</td>\n",
       "      <td>-0.001900</td>\n",
       "      <td>...</td>\n",
       "      <td>-232</td>\n",
       "      <td>4.486000</td>\n",
       "      <td>0.054000</td>\n",
       "      <td>-0.229000</td>\n",
       "      <td>0.972000</td>\n",
       "      <td>0.315000</td>\n",
       "      <td>-0.105000</td>\n",
       "      <td>296.286130</td>\n",
       "      <td>48.224670</td>\n",
       "      <td>15.714000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10507</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>125.275637</td>\n",
       "      <td>5.925329e-04</td>\n",
       "      <td>-5.925329e-04</td>\n",
       "      <td>189.575031</td>\n",
       "      <td>0.003637</td>\n",
       "      <td>-0.003637</td>\n",
       "      <td>...</td>\n",
       "      <td>-106</td>\n",
       "      <td>4.518464</td>\n",
       "      <td>0.043299</td>\n",
       "      <td>-0.075685</td>\n",
       "      <td>0.856497</td>\n",
       "      <td>0.083756</td>\n",
       "      <td>-0.050733</td>\n",
       "      <td>289.265873</td>\n",
       "      <td>42.889956</td>\n",
       "      <td>14.610173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10508</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>18.828869</td>\n",
       "      <td>4.229308e-05</td>\n",
       "      <td>-4.229308e-05</td>\n",
       "      <td>149.994876</td>\n",
       "      <td>0.001921</td>\n",
       "      <td>-0.001921</td>\n",
       "      <td>...</td>\n",
       "      <td>-105</td>\n",
       "      <td>4.456461</td>\n",
       "      <td>0.077310</td>\n",
       "      <td>-0.095414</td>\n",
       "      <td>0.930114</td>\n",
       "      <td>0.114919</td>\n",
       "      <td>-0.086470</td>\n",
       "      <td>284.788773</td>\n",
       "      <td>46.428830</td>\n",
       "      <td>14.107253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10509</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>19.839253</td>\n",
       "      <td>9.454255e-05</td>\n",
       "      <td>-9.454255e-05</td>\n",
       "      <td>147.553725</td>\n",
       "      <td>0.003931</td>\n",
       "      <td>-0.003931</td>\n",
       "      <td>...</td>\n",
       "      <td>-119</td>\n",
       "      <td>4.115264</td>\n",
       "      <td>0.068859</td>\n",
       "      <td>-0.059779</td>\n",
       "      <td>1.591587</td>\n",
       "      <td>0.154227</td>\n",
       "      <td>-0.130664</td>\n",
       "      <td>290.913831</td>\n",
       "      <td>46.829525</td>\n",
       "      <td>12.432530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10510</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12.943230</td>\n",
       "      <td>1.966610e-05</td>\n",
       "      <td>-1.966610e-05</td>\n",
       "      <td>161.414964</td>\n",
       "      <td>0.002044</td>\n",
       "      <td>-0.002044</td>\n",
       "      <td>...</td>\n",
       "      <td>-103</td>\n",
       "      <td>4.515758</td>\n",
       "      <td>0.077771</td>\n",
       "      <td>-0.031383</td>\n",
       "      <td>0.799402</td>\n",
       "      <td>0.041920</td>\n",
       "      <td>-0.070770</td>\n",
       "      <td>287.970475</td>\n",
       "      <td>48.512110</td>\n",
       "      <td>15.774562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10511</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>29.870849</td>\n",
       "      <td>1.410744e-04</td>\n",
       "      <td>-1.410744e-04</td>\n",
       "      <td>147.448887</td>\n",
       "      <td>0.003819</td>\n",
       "      <td>-0.003819</td>\n",
       "      <td>...</td>\n",
       "      <td>-98</td>\n",
       "      <td>4.604036</td>\n",
       "      <td>0.016537</td>\n",
       "      <td>-0.048907</td>\n",
       "      <td>0.737669</td>\n",
       "      <td>0.048093</td>\n",
       "      <td>-0.029537</td>\n",
       "      <td>282.945550</td>\n",
       "      <td>47.464663</td>\n",
       "      <td>11.620335</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10512 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       koi_fpflag_nt  koi_fpflag_ss  koi_fpflag_co  koi_fpflag_ec  koi_period  \\\n",
       "0                  0              0              0              0   54.418383   \n",
       "1                  0              1              0              0   19.899140   \n",
       "2                  0              1              0              0    1.736952   \n",
       "3                  0              0              0              0    2.525592   \n",
       "4                  0              0              0              0    4.134435   \n",
       "...              ...            ...            ...            ...         ...   \n",
       "10507              0              0              0              0  125.275637   \n",
       "10508              0              0              0              0   18.828869   \n",
       "10509              0              0              0              0   19.839253   \n",
       "10510              0              0              0              0   12.943230   \n",
       "10511              0              0              0              0   29.870849   \n",
       "\n",
       "       koi_period_err1  koi_period_err2  koi_time0bk  koi_time0bk_err1  \\\n",
       "0         2.479000e-04    -2.479000e-04   162.513840          0.003520   \n",
       "1         1.490000e-05    -1.490000e-05   175.850252          0.000581   \n",
       "2         2.630000e-07    -2.630000e-07   170.307565          0.000115   \n",
       "3         3.760000e-06    -3.760000e-06   171.595550          0.001130   \n",
       "4         1.050000e-05    -1.050000e-05   172.979370          0.001900   \n",
       "...                ...              ...          ...               ...   \n",
       "10507     5.925329e-04    -5.925329e-04   189.575031          0.003637   \n",
       "10508     4.229308e-05    -4.229308e-05   149.994876          0.001921   \n",
       "10509     9.454255e-05    -9.454255e-05   147.553725          0.003931   \n",
       "10510     1.966610e-05    -1.966610e-05   161.414964          0.002044   \n",
       "10511     1.410744e-04    -1.410744e-04   147.448887          0.003819   \n",
       "\n",
       "       koi_time0bk_err2  ...  koi_steff_err2  koi_slogg  koi_slogg_err1  \\\n",
       "0             -0.003520  ...             -81   4.467000        0.064000   \n",
       "1             -0.000581  ...            -176   4.544000        0.044000   \n",
       "2             -0.000115  ...            -174   4.564000        0.053000   \n",
       "3             -0.001130  ...            -211   4.438000        0.070000   \n",
       "4             -0.001900  ...            -232   4.486000        0.054000   \n",
       "...                 ...  ...             ...        ...             ...   \n",
       "10507         -0.003637  ...            -106   4.518464        0.043299   \n",
       "10508         -0.001921  ...            -105   4.456461        0.077310   \n",
       "10509         -0.003931  ...            -119   4.115264        0.068859   \n",
       "10510         -0.002044  ...            -103   4.515758        0.077771   \n",
       "10511         -0.003819  ...             -98   4.604036        0.016537   \n",
       "\n",
       "       koi_slogg_err2  koi_srad  koi_srad_err1  koi_srad_err2          ra  \\\n",
       "0           -0.096000  0.927000       0.105000      -0.061000  291.934230   \n",
       "1           -0.176000  0.868000       0.233000      -0.078000  297.004820   \n",
       "2           -0.168000  0.791000       0.201000      -0.067000  285.534610   \n",
       "3           -0.210000  1.046000       0.334000      -0.133000  288.754880   \n",
       "4           -0.229000  0.972000       0.315000      -0.105000  296.286130   \n",
       "...               ...       ...            ...            ...         ...   \n",
       "10507       -0.075685  0.856497       0.083756      -0.050733  289.265873   \n",
       "10508       -0.095414  0.930114       0.114919      -0.086470  284.788773   \n",
       "10509       -0.059779  1.591587       0.154227      -0.130664  290.913831   \n",
       "10510       -0.031383  0.799402       0.041920      -0.070770  287.970475   \n",
       "10511       -0.048907  0.737669       0.048093      -0.029537  282.945550   \n",
       "\n",
       "             dec  koi_kepmag  \n",
       "0      48.141651   15.347000  \n",
       "1      48.134129   15.436000  \n",
       "2      48.285210   15.597000  \n",
       "3      48.226200   15.509000  \n",
       "4      48.224670   15.714000  \n",
       "...          ...         ...  \n",
       "10507  42.889956   14.610173  \n",
       "10508  46.428830   14.107253  \n",
       "10509  46.829525   12.432530  \n",
       "10510  48.512110   15.774562  \n",
       "10511  47.464663   11.620335  \n",
       "\n",
       "[10512 rows x 40 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "#Oversampling the data\n",
    "y_raw = df['koi_disposition']\n",
    "X_raw = df.drop(columns='koi_disposition')\n",
    "smote = SMOTE(random_state = 1)\n",
    "X, y = smote.fit_resample(X_raw, y_raw)\n",
    "#Creating a new Oversampling Data Frame\n",
    "df_oversampler = pd.DataFrame(X)\n",
    "df_oversampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fd437b02a00>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "y\n",
    "sns.countplot(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 1, stratify = y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>koi_fpflag_nt</th>\n",
       "      <th>koi_fpflag_ss</th>\n",
       "      <th>koi_fpflag_co</th>\n",
       "      <th>koi_fpflag_ec</th>\n",
       "      <th>koi_period</th>\n",
       "      <th>koi_period_err1</th>\n",
       "      <th>koi_period_err2</th>\n",
       "      <th>koi_time0bk</th>\n",
       "      <th>koi_time0bk_err1</th>\n",
       "      <th>koi_time0bk_err2</th>\n",
       "      <th>...</th>\n",
       "      <th>koi_steff_err2</th>\n",
       "      <th>koi_slogg</th>\n",
       "      <th>koi_slogg_err1</th>\n",
       "      <th>koi_slogg_err2</th>\n",
       "      <th>koi_srad</th>\n",
       "      <th>koi_srad_err1</th>\n",
       "      <th>koi_srad_err2</th>\n",
       "      <th>ra</th>\n",
       "      <th>dec</th>\n",
       "      <th>koi_kepmag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10044</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.870948</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>-0.000069</td>\n",
       "      <td>136.032685</td>\n",
       "      <td>0.005009</td>\n",
       "      <td>-0.005009</td>\n",
       "      <td>...</td>\n",
       "      <td>-124</td>\n",
       "      <td>4.305713</td>\n",
       "      <td>0.088414</td>\n",
       "      <td>-0.079428</td>\n",
       "      <td>1.295495</td>\n",
       "      <td>0.184341</td>\n",
       "      <td>-0.178532</td>\n",
       "      <td>292.081655</td>\n",
       "      <td>44.757560</td>\n",
       "      <td>14.276923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4177</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13.026796</td>\n",
       "      <td>0.000044</td>\n",
       "      <td>-0.000044</td>\n",
       "      <td>139.147770</td>\n",
       "      <td>0.002540</td>\n",
       "      <td>-0.002540</td>\n",
       "      <td>...</td>\n",
       "      <td>-152</td>\n",
       "      <td>4.512000</td>\n",
       "      <td>0.063000</td>\n",
       "      <td>-0.070000</td>\n",
       "      <td>0.844000</td>\n",
       "      <td>0.083000</td>\n",
       "      <td>-0.074000</td>\n",
       "      <td>297.577120</td>\n",
       "      <td>40.027710</td>\n",
       "      <td>13.336000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1902</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.853739</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>-0.000012</td>\n",
       "      <td>132.668850</td>\n",
       "      <td>0.006680</td>\n",
       "      <td>-0.006680</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>5.283000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.116000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>289.847720</td>\n",
       "      <td>44.185783</td>\n",
       "      <td>12.946000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8065</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>58.306708</td>\n",
       "      <td>0.000943</td>\n",
       "      <td>-0.000943</td>\n",
       "      <td>169.624957</td>\n",
       "      <td>0.012540</td>\n",
       "      <td>-0.012540</td>\n",
       "      <td>...</td>\n",
       "      <td>-189</td>\n",
       "      <td>4.580283</td>\n",
       "      <td>0.039429</td>\n",
       "      <td>-0.137286</td>\n",
       "      <td>0.787289</td>\n",
       "      <td>0.170573</td>\n",
       "      <td>-0.072858</td>\n",
       "      <td>291.866453</td>\n",
       "      <td>45.355029</td>\n",
       "      <td>15.936563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3183</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5.357451</td>\n",
       "      <td>0.000046</td>\n",
       "      <td>-0.000046</td>\n",
       "      <td>131.627840</td>\n",
       "      <td>0.008850</td>\n",
       "      <td>-0.008850</td>\n",
       "      <td>...</td>\n",
       "      <td>-167</td>\n",
       "      <td>3.982000</td>\n",
       "      <td>0.252000</td>\n",
       "      <td>-0.108000</td>\n",
       "      <td>1.860000</td>\n",
       "      <td>0.383000</td>\n",
       "      <td>-0.527000</td>\n",
       "      <td>298.451230</td>\n",
       "      <td>46.620861</td>\n",
       "      <td>12.596000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       koi_fpflag_nt  koi_fpflag_ss  koi_fpflag_co  koi_fpflag_ec  koi_period  \\\n",
       "10044              0              0              0              0    5.870948   \n",
       "4177               0              0              0              0   13.026796   \n",
       "1902               0              1              1              0    1.853739   \n",
       "8065               0              0              0              0   58.306708   \n",
       "3183               0              0              0              1    5.357451   \n",
       "\n",
       "       koi_period_err1  koi_period_err2  koi_time0bk  koi_time0bk_err1  \\\n",
       "10044         0.000069        -0.000069   136.032685          0.005009   \n",
       "4177          0.000044        -0.000044   139.147770          0.002540   \n",
       "1902          0.000012        -0.000012   132.668850          0.006680   \n",
       "8065          0.000943        -0.000943   169.624957          0.012540   \n",
       "3183          0.000046        -0.000046   131.627840          0.008850   \n",
       "\n",
       "       koi_time0bk_err2  ...  koi_steff_err2  koi_slogg  koi_slogg_err1  \\\n",
       "10044         -0.005009  ...            -124   4.305713        0.088414   \n",
       "4177          -0.002540  ...            -152   4.512000        0.063000   \n",
       "1902          -0.006680  ...               0   5.283000        0.000000   \n",
       "8065          -0.012540  ...            -189   4.580283        0.039429   \n",
       "3183          -0.008850  ...            -167   3.982000        0.252000   \n",
       "\n",
       "       koi_slogg_err2  koi_srad  koi_srad_err1  koi_srad_err2          ra  \\\n",
       "10044       -0.079428  1.295495       0.184341      -0.178532  292.081655   \n",
       "4177        -0.070000  0.844000       0.083000      -0.074000  297.577120   \n",
       "1902         0.000000  0.116000       0.000000       0.000000  289.847720   \n",
       "8065        -0.137286  0.787289       0.170573      -0.072858  291.866453   \n",
       "3183        -0.108000  1.860000       0.383000      -0.527000  298.451230   \n",
       "\n",
       "             dec  koi_kepmag  \n",
       "10044  44.757560   14.276923  \n",
       "4177   40.027710   13.336000  \n",
       "1902   44.185783   12.946000  \n",
       "8065   45.355029   15.936563  \n",
       "3183   46.620861   12.596000  \n",
       "\n",
       "[5 rows x 40 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-processing\n",
    "\n",
    "Scale the data using the MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "X_scaler = MinMaxScaler().fit(X_train)\n",
    "\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Standardize the data using StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "X_train_stand = X_train.copy()\n",
    "X_test_stand = X_test.copy()\n",
    "\n",
    "# only numerical features\n",
    "num_cols = X.columns\n",
    "\n",
    "# apply standardization on numerical features\n",
    "for i in num_cols:\n",
    "    scale = StandardScaler().fit(X_train_stand[[i]])\n",
    "    X_train_stand[i] = scale.transform(X_train_stand[[i]])\n",
    "    X_test_stand[i] = scale.transform(X_test_stand[[i]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalized data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "model = LogisticRegression(max_iter = 1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Score: 0.8192541856925418\n",
      "Test Data Score: 0.8203957382039574\n"
     ]
    }
   ],
   "source": [
    "model.fit(X_train_scaled, y_train)\n",
    "print(f\"Training Data Score: {model.score(X_train_scaled, y_train)}\")\n",
    "print(f\"Test Data Score: {model.score(X_test_scaled, y_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Standardized data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Score: 0.8669457128361238\n",
      "Test Data Score: 0.8755707762557078\n"
     ]
    }
   ],
   "source": [
    "model.fit(X_train_stand, y_train)\n",
    "print(f\"Training Data Score: {model.score(X_train_stand, y_train)}\") # 89.17\n",
    "print(f\"Test Data Score: {model.score(X_test_stand, y_test)}\") # 88.44"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Standardization produces higher test accuracy than normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning\n",
    "\n",
    "Use `GridSearchCV` to tune the model's parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "param_grid = {'C': [1, 5, 10],\n",
    "             'penalty': [\"l1\", \"l2\"]}\n",
    "model = LogisticRegression(solver = 'liblinear')\n",
    "grid = GridSearchCV(model, param_grid, verbose = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n",
      "[CV] C=1, penalty=l1 .................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ..................... C=1, penalty=l1, score=0.854, total=   1.1s\n",
      "[CV] C=1, penalty=l1 .................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.1s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ..................... C=1, penalty=l1, score=0.843, total=   1.2s\n",
      "[CV] C=1, penalty=l1 .................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    2.3s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ..................... C=1, penalty=l1, score=0.851, total=   1.3s\n",
      "[CV] C=1, penalty=l1 .................................................\n",
      "[CV] ..................... C=1, penalty=l1, score=0.844, total=   1.2s\n",
      "[CV] C=1, penalty=l1 .................................................\n",
      "[CV] ..................... C=1, penalty=l1, score=0.845, total=   1.2s\n",
      "[CV] C=1, penalty=l2 .................................................\n",
      "[CV] ..................... C=1, penalty=l2, score=0.797, total=   0.1s\n",
      "[CV] C=1, penalty=l2 .................................................\n",
      "[CV] ..................... C=1, penalty=l2, score=0.790, total=   0.1s\n",
      "[CV] C=1, penalty=l2 .................................................\n",
      "[CV] ..................... C=1, penalty=l2, score=0.807, total=   0.1s\n",
      "[CV] C=1, penalty=l2 .................................................\n",
      "[CV] ..................... C=1, penalty=l2, score=0.800, total=   0.1s\n",
      "[CV] C=1, penalty=l2 .................................................\n",
      "[CV] ..................... C=1, penalty=l2, score=0.809, total=   0.1s\n",
      "[CV] C=5, penalty=l1 .................................................\n",
      "[CV] ..................... C=5, penalty=l1, score=0.852, total=   5.4s\n",
      "[CV] C=5, penalty=l1 .................................................\n",
      "[CV] ..................... C=5, penalty=l1, score=0.854, total=   6.1s\n",
      "[CV] C=5, penalty=l1 .................................................\n",
      "[CV] ..................... C=5, penalty=l1, score=0.860, total=  12.2s\n",
      "[CV] C=5, penalty=l1 .................................................\n",
      "[CV] ..................... C=5, penalty=l1, score=0.855, total=   7.5s\n",
      "[CV] C=5, penalty=l1 .................................................\n",
      "[CV] ..................... C=5, penalty=l1, score=0.848, total=  14.0s\n",
      "[CV] C=5, penalty=l2 .................................................\n",
      "[CV] ..................... C=5, penalty=l2, score=0.823, total=   0.2s\n",
      "[CV] C=5, penalty=l2 .................................................\n",
      "[CV] ..................... C=5, penalty=l2, score=0.817, total=   0.2s\n",
      "[CV] C=5, penalty=l2 .................................................\n",
      "[CV] ..................... C=5, penalty=l2, score=0.826, total=   0.2s\n",
      "[CV] C=5, penalty=l2 .................................................\n",
      "[CV] ..................... C=5, penalty=l2, score=0.829, total=   0.2s\n",
      "[CV] C=5, penalty=l2 .................................................\n",
      "[CV] ..................... C=5, penalty=l2, score=0.832, total=   0.2s\n",
      "[CV] C=10, penalty=l1 ................................................\n",
      "[CV] .................... C=10, penalty=l1, score=0.855, total=  27.2s\n",
      "[CV] C=10, penalty=l1 ................................................\n",
      "[CV] .................... C=10, penalty=l1, score=0.852, total=  34.2s\n",
      "[CV] C=10, penalty=l1 ................................................\n",
      "[CV] .................... C=10, penalty=l1, score=0.861, total=  29.3s\n",
      "[CV] C=10, penalty=l1 ................................................\n",
      "[CV] .................... C=10, penalty=l1, score=0.859, total=  28.6s\n",
      "[CV] C=10, penalty=l1 ................................................\n",
      "[CV] .................... C=10, penalty=l1, score=0.852, total=  27.2s\n",
      "[CV] C=10, penalty=l2 ................................................\n",
      "[CV] .................... C=10, penalty=l2, score=0.836, total=   0.2s\n",
      "[CV] C=10, penalty=l2 ................................................\n",
      "[CV] .................... C=10, penalty=l2, score=0.831, total=   0.2s\n",
      "[CV] C=10, penalty=l2 ................................................\n",
      "[CV] .................... C=10, penalty=l2, score=0.834, total=   0.2s\n",
      "[CV] C=10, penalty=l2 ................................................\n",
      "[CV] .................... C=10, penalty=l2, score=0.833, total=   0.2s\n",
      "[CV] C=10, penalty=l2 ................................................\n",
      "[CV] .................... C=10, penalty=l2, score=0.836, total=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed:  3.3min finished\n",
      "/Users/jiaping/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=LogisticRegression(solver='liblinear'),\n",
       "             param_grid={'C': [1, 5, 10], 'penalty': ['l1', 'l2']}, verbose=3)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 10, 'penalty': 'l1'}\n",
      "0.8557834061332157\n"
     ]
    }
   ],
   "source": [
    "print(grid.best_params_)\n",
    "print(grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Acc: 0.870\n"
     ]
    }
   ],
   "source": [
    "predictions1 = grid.predict(X_test_scaled)\n",
    "print('Test Acc: %.3f' % grid.score(X_test_scaled, y_test)) # 0.881"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                precision    recall  f1-score   support\n",
      "\n",
      "     CANDIDATE       0.85      0.75      0.80       876\n",
      "     CONFIRMED       0.78      0.87      0.82       876\n",
      "FALSE POSITIVE       0.98      1.00      0.99       876\n",
      "\n",
      "      accuracy                           0.87      2628\n",
      "     macro avg       0.87      0.87      0.87      2628\n",
      "  weighted avg       0.87      0.87      0.87      2628\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, predictions1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After tuning the model using grid search, the logistic regression model accuracy is inceased from 85% to 88%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Standardized data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n",
      "[CV] C=1, penalty=l1 .................................................\n",
      "[CV] ..................... C=1, penalty=l1, score=0.859, total=   5.4s\n",
      "[CV] C=1, penalty=l1 .................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    5.4s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ..................... C=1, penalty=l1, score=0.853, total=   1.1s\n",
      "[CV] C=1, penalty=l1 .................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    6.4s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ..................... C=1, penalty=l1, score=0.857, total=   2.1s\n",
      "[CV] C=1, penalty=l1 .................................................\n",
      "[CV] ..................... C=1, penalty=l1, score=0.859, total=   3.0s\n",
      "[CV] C=1, penalty=l1 .................................................\n",
      "[CV] ..................... C=1, penalty=l1, score=0.848, total=   2.8s\n",
      "[CV] C=1, penalty=l2 .................................................\n",
      "[CV] ..................... C=1, penalty=l2, score=0.864, total=   0.4s\n",
      "[CV] C=1, penalty=l2 .................................................\n",
      "[CV] ..................... C=1, penalty=l2, score=0.852, total=   0.4s\n",
      "[CV] C=1, penalty=l2 .................................................\n",
      "[CV] ..................... C=1, penalty=l2, score=0.852, total=   0.3s\n",
      "[CV] C=1, penalty=l2 .................................................\n",
      "[CV] ..................... C=1, penalty=l2, score=0.859, total=   0.3s\n",
      "[CV] C=1, penalty=l2 .................................................\n",
      "[CV] ..................... C=1, penalty=l2, score=0.848, total=   0.4s\n",
      "[CV] C=5, penalty=l1 .................................................\n",
      "[CV] ..................... C=5, penalty=l1, score=0.862, total=   4.0s\n",
      "[CV] C=5, penalty=l1 .................................................\n",
      "[CV] ..................... C=5, penalty=l1, score=0.857, total=   3.3s\n",
      "[CV] C=5, penalty=l1 .................................................\n",
      "[CV] ..................... C=5, penalty=l1, score=0.857, total=   4.4s\n",
      "[CV] C=5, penalty=l1 .................................................\n",
      "[CV] ..................... C=5, penalty=l1, score=0.862, total=   4.3s\n",
      "[CV] C=5, penalty=l1 .................................................\n",
      "[CV] ..................... C=5, penalty=l1, score=0.850, total=   4.6s\n",
      "[CV] C=5, penalty=l2 .................................................\n",
      "[CV] ..................... C=5, penalty=l2, score=0.862, total=   0.6s\n",
      "[CV] C=5, penalty=l2 .................................................\n",
      "[CV] ..................... C=5, penalty=l2, score=0.855, total=   0.5s\n",
      "[CV] C=5, penalty=l2 .................................................\n",
      "[CV] ..................... C=5, penalty=l2, score=0.856, total=   0.7s\n",
      "[CV] C=5, penalty=l2 .................................................\n",
      "[CV] ..................... C=5, penalty=l2, score=0.860, total=   0.5s\n",
      "[CV] C=5, penalty=l2 .................................................\n",
      "[CV] ..................... C=5, penalty=l2, score=0.852, total=   0.7s\n",
      "[CV] C=10, penalty=l1 ................................................\n",
      "[CV] .................... C=10, penalty=l1, score=0.863, total=   5.5s\n",
      "[CV] C=10, penalty=l1 ................................................\n",
      "[CV] .................... C=10, penalty=l1, score=0.858, total=   4.8s\n",
      "[CV] C=10, penalty=l1 ................................................\n",
      "[CV] .................... C=10, penalty=l1, score=0.857, total=   3.9s\n",
      "[CV] C=10, penalty=l1 ................................................\n",
      "[CV] .................... C=10, penalty=l1, score=0.862, total=   5.3s\n",
      "[CV] C=10, penalty=l1 ................................................\n",
      "[CV] .................... C=10, penalty=l1, score=0.851, total=   6.1s\n",
      "[CV] C=10, penalty=l2 ................................................\n",
      "[CV] .................... C=10, penalty=l2, score=0.861, total=   1.1s\n",
      "[CV] C=10, penalty=l2 ................................................\n",
      "[CV] .................... C=10, penalty=l2, score=0.856, total=   0.8s\n",
      "[CV] C=10, penalty=l2 ................................................\n",
      "[CV] .................... C=10, penalty=l2, score=0.857, total=   0.7s\n",
      "[CV] C=10, penalty=l2 ................................................\n",
      "[CV] .................... C=10, penalty=l2, score=0.862, total=   0.6s\n",
      "[CV] C=10, penalty=l2 ................................................\n",
      "[CV] .................... C=10, penalty=l2, score=0.851, total=   1.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed:  1.2min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=LogisticRegression(solver='liblinear'),\n",
       "             param_grid={'C': [1, 5, 10], 'penalty': ['l1', 'l2']}, verbose=3)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.fit(X_train_stand, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 10, 'penalty': 'l1'}\n",
      "0.8580660606626346\n"
     ]
    }
   ],
   "source": [
    "print(grid.best_params_)\n",
    "print(grid.best_score_) # 88.4%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Acc: 0.874\n"
     ]
    }
   ],
   "source": [
    "predictions2 = grid.predict(X_test_stand)\n",
    "print('Test Acc: %.3f' % grid.score(X_test_stand, y_test)) # 88.1%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                precision    recall  f1-score   support\n",
      "\n",
      "     CANDIDATE       0.86      0.75      0.80       876\n",
      "     CONFIRMED       0.79      0.87      0.83       876\n",
      "FALSE POSITIVE       0.98      1.00      0.99       876\n",
      "\n",
      "      accuracy                           0.87      2628\n",
      "     macro avg       0.88      0.87      0.87      2628\n",
      "  weighted avg       0.88      0.87      0.87      2628\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, predictions2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the training set cross validation results, the tuned model with standardized data (CV=88.4%) performs slightly better than the tuned model with normalized data (CV=88.1%). As for the final test set accuracy, they have same performance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['logistic.sav']"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "filename = 'logistic.sav'\n",
    "joblib.dump(grid, filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predictions from the tuned model with normalized data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Actual</th>\n",
       "      <th>Predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>CONFIRMED</td>\n",
       "      <td>CONFIRMED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4595</th>\n",
       "      <td>FALSE POSITIVE</td>\n",
       "      <td>FALSE POSITIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1027</th>\n",
       "      <td>CANDIDATE</td>\n",
       "      <td>CONFIRMED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3087</th>\n",
       "      <td>CANDIDATE</td>\n",
       "      <td>CANDIDATE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3534</th>\n",
       "      <td>FALSE POSITIVE</td>\n",
       "      <td>FALSE POSITIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>528</th>\n",
       "      <td>CONFIRMED</td>\n",
       "      <td>CONFIRMED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8314</th>\n",
       "      <td>CANDIDATE</td>\n",
       "      <td>CANDIDATE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8512</th>\n",
       "      <td>CANDIDATE</td>\n",
       "      <td>CANDIDATE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2744</th>\n",
       "      <td>CANDIDATE</td>\n",
       "      <td>CANDIDATE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8236</th>\n",
       "      <td>CANDIDATE</td>\n",
       "      <td>CONFIRMED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1575</th>\n",
       "      <td>FALSE POSITIVE</td>\n",
       "      <td>FALSE POSITIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7570</th>\n",
       "      <td>CANDIDATE</td>\n",
       "      <td>CANDIDATE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6771</th>\n",
       "      <td>FALSE POSITIVE</td>\n",
       "      <td>FALSE POSITIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10257</th>\n",
       "      <td>CONFIRMED</td>\n",
       "      <td>CONFIRMED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5748</th>\n",
       "      <td>FALSE POSITIVE</td>\n",
       "      <td>FALSE POSITIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5479</th>\n",
       "      <td>FALSE POSITIVE</td>\n",
       "      <td>FALSE POSITIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10219</th>\n",
       "      <td>CONFIRMED</td>\n",
       "      <td>CONFIRMED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>506</th>\n",
       "      <td>CONFIRMED</td>\n",
       "      <td>CONFIRMED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>FALSE POSITIVE</td>\n",
       "      <td>FALSE POSITIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>818</th>\n",
       "      <td>CONFIRMED</td>\n",
       "      <td>CONFIRMED</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Actual       Predicted\n",
       "171         CONFIRMED       CONFIRMED\n",
       "4595   FALSE POSITIVE  FALSE POSITIVE\n",
       "1027        CANDIDATE       CONFIRMED\n",
       "3087        CANDIDATE       CANDIDATE\n",
       "3534   FALSE POSITIVE  FALSE POSITIVE\n",
       "528         CONFIRMED       CONFIRMED\n",
       "8314        CANDIDATE       CANDIDATE\n",
       "8512        CANDIDATE       CANDIDATE\n",
       "2744        CANDIDATE       CANDIDATE\n",
       "8236        CANDIDATE       CONFIRMED\n",
       "1575   FALSE POSITIVE  FALSE POSITIVE\n",
       "7570        CANDIDATE       CANDIDATE\n",
       "6771   FALSE POSITIVE  FALSE POSITIVE\n",
       "10257       CONFIRMED       CONFIRMED\n",
       "5748   FALSE POSITIVE  FALSE POSITIVE\n",
       "5479   FALSE POSITIVE  FALSE POSITIVE\n",
       "10219       CONFIRMED       CONFIRMED\n",
       "506         CONFIRMED       CONFIRMED\n",
       "73     FALSE POSITIVE  FALSE POSITIVE\n",
       "818         CONFIRMED       CONFIRMED"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction1_df = pd.DataFrame({\"Actual\": y_test, \"Predicted\":predictions1})\n",
    "prediction1_df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of total predictions: 2628\n",
      "The number of correct predictions: 2286\n",
      "The test test accuracy: 86.99%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Int64Index([1027, 8236, 8286, 9190, 3602, 4558, 8041, 8132, 8472, 3327,\n",
       "            ...\n",
       "            8074, 7078, 7930, 9091, 2074, 9531, 3397, 8652, 9441, 1768],\n",
       "           dtype='int64', length=342)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction1_df['match'] = np.where(prediction1_df['Predicted'] == prediction1_df['Actual'], 1, 0)\n",
    "print(f\"The number of total predictions: {len(prediction1_df)}\")\n",
    "print(f\"The number of correct predictions: {sum(prediction1_df['match'])}\")\n",
    "print(f\"The test test accuracy: {round(sum(prediction1_df['match'])/len(prediction1_df)*100,2)}%\")\n",
    "prediction1_df[prediction1_df['match']==0].index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predictions from the tuned model with standardized data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Actual</th>\n",
       "      <th>Predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>CONFIRMED</td>\n",
       "      <td>CONFIRMED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4595</th>\n",
       "      <td>FALSE POSITIVE</td>\n",
       "      <td>FALSE POSITIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1027</th>\n",
       "      <td>CANDIDATE</td>\n",
       "      <td>CONFIRMED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3087</th>\n",
       "      <td>CANDIDATE</td>\n",
       "      <td>CANDIDATE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3534</th>\n",
       "      <td>FALSE POSITIVE</td>\n",
       "      <td>FALSE POSITIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>528</th>\n",
       "      <td>CONFIRMED</td>\n",
       "      <td>CONFIRMED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8314</th>\n",
       "      <td>CANDIDATE</td>\n",
       "      <td>CANDIDATE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8512</th>\n",
       "      <td>CANDIDATE</td>\n",
       "      <td>CANDIDATE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2744</th>\n",
       "      <td>CANDIDATE</td>\n",
       "      <td>CANDIDATE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8236</th>\n",
       "      <td>CANDIDATE</td>\n",
       "      <td>CONFIRMED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1575</th>\n",
       "      <td>FALSE POSITIVE</td>\n",
       "      <td>FALSE POSITIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7570</th>\n",
       "      <td>CANDIDATE</td>\n",
       "      <td>CANDIDATE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6771</th>\n",
       "      <td>FALSE POSITIVE</td>\n",
       "      <td>FALSE POSITIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10257</th>\n",
       "      <td>CONFIRMED</td>\n",
       "      <td>CONFIRMED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5748</th>\n",
       "      <td>FALSE POSITIVE</td>\n",
       "      <td>FALSE POSITIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5479</th>\n",
       "      <td>FALSE POSITIVE</td>\n",
       "      <td>FALSE POSITIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10219</th>\n",
       "      <td>CONFIRMED</td>\n",
       "      <td>CONFIRMED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>506</th>\n",
       "      <td>CONFIRMED</td>\n",
       "      <td>CONFIRMED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>FALSE POSITIVE</td>\n",
       "      <td>FALSE POSITIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>818</th>\n",
       "      <td>CONFIRMED</td>\n",
       "      <td>CONFIRMED</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Actual       Predicted\n",
       "171         CONFIRMED       CONFIRMED\n",
       "4595   FALSE POSITIVE  FALSE POSITIVE\n",
       "1027        CANDIDATE       CONFIRMED\n",
       "3087        CANDIDATE       CANDIDATE\n",
       "3534   FALSE POSITIVE  FALSE POSITIVE\n",
       "528         CONFIRMED       CONFIRMED\n",
       "8314        CANDIDATE       CANDIDATE\n",
       "8512        CANDIDATE       CANDIDATE\n",
       "2744        CANDIDATE       CANDIDATE\n",
       "8236        CANDIDATE       CONFIRMED\n",
       "1575   FALSE POSITIVE  FALSE POSITIVE\n",
       "7570        CANDIDATE       CANDIDATE\n",
       "6771   FALSE POSITIVE  FALSE POSITIVE\n",
       "10257       CONFIRMED       CONFIRMED\n",
       "5748   FALSE POSITIVE  FALSE POSITIVE\n",
       "5479   FALSE POSITIVE  FALSE POSITIVE\n",
       "10219       CONFIRMED       CONFIRMED\n",
       "506         CONFIRMED       CONFIRMED\n",
       "73     FALSE POSITIVE  FALSE POSITIVE\n",
       "818         CONFIRMED       CONFIRMED"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction2_df = pd.DataFrame({\"Actual\": y_test, \"Predicted\":predictions2})\n",
    "prediction2_df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of total predictions: 2628\n",
      "The number of correct predictions: 2297\n",
      "The test test accuracy: 87.4%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Int64Index([1027, 8236, 8286, 9190, 3602, 4558, 8041, 8132, 8472, 3327,\n",
       "            ...\n",
       "            4962, 8074, 7078, 9091, 2074, 3397, 8652, 9969, 9441, 1768],\n",
       "           dtype='int64', length=331)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction2_df['match'] = np.where(prediction2_df['Predicted'] == prediction2_df['Actual'], 1, 0)\n",
    "print(f\"The number of total predictions: {len(prediction2_df)}\")\n",
    "print(f\"The number of correct predictions: {sum(prediction2_df['match'])}\")\n",
    "print(f\"The test test accuracy: {round(sum(prediction2_df['match'])/len(prediction2_df)*100,2)}%\")\n",
    "prediction2_df[prediction2_df['match']==0].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final accuracy results are consistent with the model scores obtained from the last section."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
